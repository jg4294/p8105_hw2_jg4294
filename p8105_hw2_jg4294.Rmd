---
title: "Homework 2"
author: "JingYao Geng"
output: github_document
---

```{r setup, message = FALSE, echo = FALSE}
# Clean all objects from the current workspace (R memory) 
rm(list = ls())
# load packages
library(tidyverse)
library(readxl)
```


## Problem 1

#### **Read the Mr.Trashwheel dataset.**

```{r Alternative, eval = FALSE, echo = FALSE}
# First, define a path to the dataset.
# path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"

#trashwheel_df = 
  
#read_xlsx(
   `#path = path_to_data,
 `  #sheet = "Mr. Trash Wheel",
    #range = cell_cols("A:N")) %>%
  #janitor::clean_names() %>%
  #drop_na(dumpster) %>% 
  #mutate(
    #sports_balls = round(sports_balls),
    #sports_balls = as.integer(sports_balls)
  #)

```

```{r trashwheel_df, collapse = TRUE, message = FALSE}
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
head(trashwheel_df)
```


#### **Read precipitation data for 2018 and 2017.**

**2018:**
```{r precip_2018, message = FALSE, collapse = TRUE}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1) %>%
  janitor::clean_names() %>%
  drop_na(month) %>% #drop the row based on the missing values in var. 'month'
  mutate(year = 2018) %>%
  relocate(year)

precip_2018
```

**2017:**

```{r precip_2017, message = FALSE, collapse = TRUE}
precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1) %>%
  janitor::clean_names() %>%
  drop_na(month) %>% #drop the row based on the missing values in var. 'month'
  mutate(year = 2017) %>%
  relocate(year)

precip_2017
```


**Now combine annual precipitation:**

```{r combine precip, echo = TRUE, collapse = TRUE}
# create a data frame for month
month_df = 
  tibble(
    month = 1:12, 
    month_name = month.name
  )

# row-combine precip_2018 and precip_2017
precip_df = 
  bind_rows(precip_2018, precip_2017) 
  # Type: bind_rows(precp_2018, precp_2017) %>% view in the console to view it.
  # character vector that built in r: month.abb, month.name
  # convert month number to month name: mutate(month = month.name[month])

# left-join: 
precip_m = left_join(precip_df, month_df, by = "month") 
head(precip_m) 
```

This dataset contains information from the Mr.Trashwheel trash collector in Baltimore, Maryland. As trash enters the  inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include monthly precipitation for year 2017 and 2018. The total monthly precipitation for year 2017 is `r sum(pull(precip_2017, total))` (in). The total monthly precipitation for year 2018 is `r sum(pull(precip_2018, total))` (in). 

\newpage
## Problem 2

**Read and Clean the NYC Transit dataset**
```{r transit_df, collapse = TRUE, message = FALSE}
# Clean all objects from the current workspace (R memory) 
rm(list = ls())
# read the dataset
transit_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  # data clean
  janitor::clean_names() %>%
  # retain columns we are interested in analyzing.
  select(line:entry, vending, ada)  %>%
  # recode 'entry' from a character variable into a logical variable.
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE)) 

head(transit_df)
```

* This dataset contains information for subway stations in New York City in terms of the entrance and exit. This dataset has a total number of `r nrow(transit_df)` observations and `r ncol(transit_df)` columns that we are interested in analyzing. (They are line, station name, latitude, longitude, entry, entrance_type, vending, ada, and route1 to route11.) 
* So far, we cleaned the columns name based on a consistent naming convention: snake_case, and we also re-coded the character variable 'entry' as a logical variable for further analyses.
* To me, this dataset is very odd and is definitely not tidy at all. For example, the columns route1 to route11 look quite strange, and they are not easy to interpret. Because of that, we need tidy the dataset to make it more readable and understandable.

* By identidying both name and line of the stations, we find that there are
`r transit_df %>% distinct(station_name, line) %>% nrow ` distinct stations in the NYC transits dataset. 

* Among those stations, 
`r transit_df %>% distinct(station_name, line, ada) %>% filter(ada == TRUE) %>% nrow ` stations are ADA compliant.

* The proportion of station entrances/exits without vending allow entrance are `r (filter(transit_df, vending == "NO", entry =="TRUE") %>% nrow / filter(transit_df, vending == "NO") %>% nrow)*100`%.


**Tidy data**:

Reformat data so that route number and route name are distinct variables. 

```{r transit_tidy, message = FALSE}
transit_tidy = 
  transit_df %>% 
  # convert variable 'route1' to 'route11' into character variables.
  mutate_at(vars(route1:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name", 
    names_prefix = "route_name",
    values_to = "route_number") %>% 
  # drop missing values in variable 'route_number'
  drop_na(route_number) 

head(transit_tidy)
```

* There are `r transit_tidy %>% filter(route_number == "A") %>% distinct(station_name, line) %>% count()` stations serve the A train. 
* Among these stations, `r transit_tidy %>% filter(route_number == "A") %>% distinct(station_name, line, ada) %>% filter(ada == "TRUE") %>% count()` of them are ADA compliant.

\newpage
## Question 3

##### The dataset: pols.csv
```{r pols_df+tidy, message = FALSE, collapse = TRUE}
pols_tidy = 
  # read and the dataset
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate(mon,  c("year", "month", "day")) %>% # break up variable 'mon' into 'year', 'month', and 'day'
  mutate(month = as.numeric(month)) %>% #convert
  relocate(prez_gop, prez_dem, everything()) %>% # relocate 'prez_gop', 'prez-dem' to the front.
  
  pivot_longer(
    prez_gop:prez_dem,
    names_to = "president",
    names_prefix = "prez_",
    values_to = "value") %>% # create variable 'president' to be either gop or dem
  
  filter(value == 1) %>% 
  select(-day, -value)  # drop 'day' and 'value'

# create a data frame for month            
month_df = 
  tibble(
    month = 1:12, 
    month_name = month.name) 

# tidy the pols_df
pols_tidy_month = 
  left_join(pols_tidy, month_df, by = "month") %>%
  select(-month) %>% # delete column 'month'
  relocate(year,month_name, president, everything()) %>% # relocate year, month_name, president to the front.
  rename(month = month_name) #rename 'month_name' as 'month'

head(pols_tidy_month)
  
```

##### The dataset: snp.csv
```{r snp_df+tidy, message = FALSE, collapse = TRUE}
# read and clean the snp.csv dataset
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% # clean the data
  separate(date, into = c("month", "day", "year")) %>%  # separate the variable 'date' into 3 parts.
  mutate(month = as.numeric(month)) %>%
  arrange(year, month) # arrange the data first by year then by month

snp_tidy = 
  left_join(snp_df, month_df, by = "month") %>% 
  relocate(year, month_name, close) %>%  # relocate the sequnence of variables
         select(-month, -day) %>% # drop 'month' and 'day'
         rename(month = month_name) 
head(snp_tidy)          
         
```


##### The dataset: unemployment.csv
```{r unemp_df, message = FALSE, collapse = TRUE}
unem_df = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() 

unem_tidy = 
  unem_df %>%
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemploymeny_rate") %>%
  mutate(month = recode(month,"jan" = "January",
                      "feb" = "February",
                      "mar" = "March",
                      "apr" = "April",
                      "may" = "May",
                      "jun" = "June",
                      "jul" = "July",
                      "aug" = "August",
                      "sep" = "September",
                      "oct" = "October",
                      "nov" = "November",
                      "dec" = "December")) %>% 
  mutate_at(vars(year),as.character)

head(unem_tidy)
```


##### Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r result_df, message = FALSE, collapse = TRUE}
result_df = pols_tidy_month %>%
          left_join(snp_tidy, by = c("year", "month")) %>%
          left_join(unem_tidy, by = c("year", "month"))
head(result_df) # take a look 
```

##### Summary:

* The pols dataset contains political data started from year `r min(pols_tidy$year)` to year `r max(pols_tidy$year)`. From the pols dataset we find some interesting variable like the number of different parties' governors, senators, and so on. The dimension of the original pols dataset is 882 by 11. The tidy-version of pols dataset has `r nrow(pols_tidy)` rows and `r ncol(pols_tidy)` columns.

* The snp datase contains the closing values of the Standard & Poorâ€™s stock market index on the associated date between year `r min(snp_tidy$year)` and `r max(snp_tidy$year)`. The original snp dataset only contains 2 variables: date and close. After the step of tidy data, the tidy-version of snp dataset has `r ncol(snp_tidy)` columns and `r nrow(snp_tidy)` rows.

* The unemployment dataset contains the dataset of unemployment rate at the period of year `r min(unem_tidy$year)` to year `r max(unem_tidy$year)`.

* The final dataset merged pols dataset, snp dataset, and unemployment dataset together. There are `r nrow(result_df)` observations of `r ncol(result_df)` variables. The range of year is from `r min(pull(result_df, year))` to `r max(pull(result_df, year))`. The key variables are: `r colnames(result_df[3:11])`.






